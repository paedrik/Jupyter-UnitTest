{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Driven Development in Jupyter Notebooks?\n",
    "\n",
    "I wanted to see if you can do test driven development in Jupyter notebooks and the short answer is you can!\n",
    "\n",
    "There are two ways I'm aware of to do unit testing in Python:\n",
    "   * [Unit Test](https://docs.python.org/3/library/unittest.html)\n",
    "       * Write unit test script test_{script}.py or {script}_test.py\n",
    "       * Use the unittest \n",
    "   * [DocString Test](https://pythontesting.net/framework/doctest/doctest-introduction/)\n",
    "       * Write the command and output you would get in the Python interpreter CLI (command line interface) into the Docstring for the function\n",
    "       \n",
    "They both appear to work and I tried the unittest with both imported external python files and code defined only in the Jupyter Noteboook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unit Test Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got this example from [YouTube Socratica](https://www.youtube.com/watch?v=1Lfv5tUGsn8) for testing using the Unittest library. I didn't try the DocString test method here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code is explicitly writen in the Jupyter Notebook.\n",
    "\n",
    "First lets build a function to calculate the circumference of a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "def circle_area(r):\n",
    "  if type(r) not in [int, float]:\n",
    "    raise TypeError(\"The radius must be a non-negative real number.\")\n",
    "\n",
    "  if r < 0:\n",
    "    raise ValueError(\"The radius cannot be negative.\")\n",
    "  return pi*(r**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.566370614359172\n"
     ]
    }
   ],
   "source": [
    "print(circle_area(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "print(circle_area(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the unit test script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_area (__main__.TestCircleArea) ... ok\n",
      "test_types (__main__.TestCircleArea) ... ok\n",
      "test_values (__main__.TestCircleArea) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.031s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2265a0211d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "from circles import circle_area\n",
    "from math import pi\n",
    "\n",
    "class TestCircleArea(unittest.TestCase):\n",
    "  def test_area(self):\n",
    "    # Test areas when radius >= 0\n",
    "    self.assertAlmostEqual(circle_area(1), pi)\n",
    "    self.assertAlmostEqual(circle_area(0), 0)\n",
    "    self.assertAlmostEqual(circle_area(2.1), pi * 2.1**2)\n",
    "    \n",
    "\n",
    "  def test_values(self):\n",
    "    # Make sure value errors are raised when necessary\n",
    "    self.assertRaises(ValueError, circle_area, -2)\n",
    "\n",
    "  def test_types(self):\n",
    "    # Make sure type errors are raised when necessary\n",
    "    self.assertRaises(TypeError, circle_area, 5 + 6j)\n",
    "    self.assertRaises(TypeError, circle_area, \"radius\")\n",
    "    \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code is in a external python files\n",
    "\n",
    "In this case there are two files:\n",
    "\n",
    "   - circles.py\n",
    "   - test_circles.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_area (test_circles.TestCircleArea) ... ok\n",
      "test_types (test_circles.TestCircleArea) ... ok\n",
      "test_values (test_circles.TestCircleArea) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.023s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2265a0209b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "from test_circles import TestCircleArea\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DocString Test method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pass Example\n",
    "Module showing how doctests can be included with source code\n",
    "Each '>>>' line is run as if in a python shell, and counts as a test.\n",
    "The next line, if not '>>>' is the expected output of the previous line.\n",
    "If anything doesn't match exactly (including trailing spaces), the test fails.\n",
    "'''\n",
    " \n",
    "def multiply(a, b):\n",
    "    \"\"\"\n",
    "    >>> multiply(4, 3)\n",
    "    12\n",
    "    >>> multiply('a', 3)\n",
    "    'aaa'\n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import doctest then run it normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the doctest in verbose mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    multiply(4, 3)\n",
      "Expecting:\n",
      "    12\n",
      "ok\n",
      "Trying:\n",
      "    multiply('a', 3)\n",
      "Expecting:\n",
      "    'aaa'\n",
      "ok\n",
      "1 items had no tests:\n",
      "    __main__\n",
      "1 items passed all tests:\n",
      "   2 tests in __main__.multiply\n",
      "2 tests in 2 items.\n",
      "2 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an example that will fail (looking for 2+2=5 in the test).\n",
    "\n",
    "You can see that it runs the initial multiply() still but it runs them in alphabetical order so add() goes first.\n",
    "\n",
    "Again run it normally then in verbose mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Failure Example\n",
    "Module showing how doctests can be included with source code\n",
    "Each '>>>' line is run as if in a python shell, and counts as a test.\n",
    "The next line, if not '>>>' is the expected output of the previous line.\n",
    "If anything doesn't match exactly (including trailing spaces), the test fails.\n",
    "'''\n",
    "def add(a, b):\n",
    "    '''\n",
    "    This is a test:\n",
    "    >>> add(2, 2)\n",
    "    5\n",
    "    '''\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 11, in __main__.add\n",
      "Failed example:\n",
      "    add(2, 2)\n",
      "Expected:\n",
      "    5\n",
      "Got:\n",
      "    4\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   1 of   1 in __main__.add\n",
      "***Test Failed*** 1 failures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=1, attempted=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    add(2, 2)\n",
      "Expecting:\n",
      "    5\n",
      "**********************************************************************\n",
      "File \"__main__\", line 11, in __main__.add\n",
      "Failed example:\n",
      "    add(2, 2)\n",
      "Expected:\n",
      "    5\n",
      "Got:\n",
      "    4\n",
      "Trying:\n",
      "    multiply(4, 3)\n",
      "Expecting:\n",
      "    12\n",
      "ok\n",
      "Trying:\n",
      "    multiply('a', 3)\n",
      "Expecting:\n",
      "    'aaa'\n",
      "ok\n",
      "1 items had no tests:\n",
      "    __main__\n",
      "1 items passed all tests:\n",
      "   2 tests in __main__.multiply\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   1 of   1 in __main__.add\n",
      "3 tests in 3 items.\n",
      "2 passed and 1 failed.\n",
      "***Test Failed*** 1 failures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=1, attempted=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
